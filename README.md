# Recommendation System for Carrefour eCommerce

[NOTE! Project is ongoing. Please see the [https://github.com/ZahirAhmadChaudhry/Recommendation_Systems_Kaggle/blob/main/Presentation/Recommendation_systems_Kaggle.pdf](Presentation) for latest updates on the project]


This repository chronicles an ongoing journey to build a highly effective recommendation system for predicting the first product a customer will repurchase on Carrefour’s eCommerce platform in 2024. Our starting point involved dissecting transaction records across 100,000+ customers, detailed product catalogs, and partially masked future purchases that serve as the validation and test targets. We began our work by constructing rudimentary baselines, such as a global popularity ranking that simply tallied the most frequently purchased items, and a recency-based model that prioritized items acquired in the latest transactions. Although these methods offered a quick proof of concept, they struggled to capture the intricacies of user-specific buying patterns.

We then introduced a time-weighted frequency mechanism that exponentially down-weighted older purchases while giving prominence to more recent transactions. This approach helped us achieve an intermediate performance, and it laid the foundation for a family of hybrid models that combined recency, frequency, and seasonality. In our hybrid experiments, we also recognized that customers are not homogeneous; some shop very frequently, whereas others make only occasional purchases. Consequently, we segmented our customers into high-, medium-, and low-frequency tiers, introducing different weight distributions for recency and frequency signals in each segment. This segmentation yielded a promising Hitrate@10 in the range of 0.36, far surpassing the earlier baselines.

With the baseline and hybrid approaches in place, we transitioned to more advanced deep learning methods. First, we explored a Neural Graph Collaborative Filtering (NGCF) framework that constructs a bipartite graph between users and items. Through multi-layer propagation, the NGCF model refines user and item embeddings by focusing on high-order connectivity, although the tremendous class imbalance demanded a carefully engineered negative sampling scheme. We tackled this through a probabilistic negative sampling pipeline that selects non-purchased items according to both popularity and recency weights, ensuring that the model sees a balanced, yet challenging, set of examples during training. We then employed GPU-accelerated computation and partial data ingestion on SLURM, gradually scaling up our experiments to handle larger data chunks.

In parallel, we introduced a two-tower architecture, where user and item embeddings are learned independently in two separate neural stacks before being combined in a final interaction layer. This approach leveraged a sophisticated randomized sampling algorithm to preserve distributional characteristics of the original dataset, drawing on the Kolmogorov–Smirnov test for rigorous validation. We also adopted a flexible ratio of negative to positive samples (often 2:1) to present more informative examples to the model. Our pipeline’s modularity enables on-the-fly data loading and feature processing, mitigating memory constraints on massive datasets.

Currently, we continue to refine these neural architectures by fine-tuning hyperparameters such as learning rate schedules, batch sizes, and layer dimensions. We have also introduced standardized best practices, such as early stopping and model regularization, to safeguard against overfitting on smaller training subsets. To date, we have validated our pipeline’s integrity on roughly 10% of the complete dataset, and early results suggest further gains can be achieved as we move to larger samples. Our plan involves completing the full integration of Neural Graph Collaborative Filtering, scaling up the two-tower approach, and systematically benchmarking both methods against ensemble-based models such as GBM, XGBoost, and LightGBM. Although this project remains a work in progress, it underscores the combined strengths of graph-based embeddings, negative sampling, and robust data engineering in tackling real-world recommender challenges at scale.

## References

- Wang, Xiang, et al. "Neural graph collaborative filtering." *SIGIR* (2019)  
- Smirnov, N. "Table for estimating the goodness of fit of empirical distributions." *The Annals of Mathematical Statistics* (1948)